{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13357.66it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 15839.52it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 23537.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import randint, random, uniform\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from utils.tdPsola import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# METHOD='Librosa'\n",
    "METHOD = \"Morphvox_Pro\"\n",
    "# METHOD = \"TD-PSOLA\"\n",
    "\n",
    "\n",
    "dirName = [\"train\", \"valid\", \"pitchShiftTest\"]\n",
    "MorphvoxPro = range(1,5)\n",
    "trainFolders: list = sorted(os.listdir(f\"./{dirName[0]}/\"))\n",
    "validFolders: list = sorted(os.listdir(f\"./{dirName[1]}/\"))\n",
    "pitchShiftFolders: list = sorted(os.listdir(f\"./{dirName[2]}/\"))\n",
    "Folders = [trainFolders, validFolders, pitchShiftFolders]\n",
    "\n",
    "# categorys: list = [f\"{i}\".rjust(2, \"0\") for i in range(1, 11)]\n",
    "DATA: dict = {}\n",
    "DATA[f\"{dirName[0]}\"] = []\n",
    "DATA[f\"{dirName[1]}\"] = []\n",
    "DATA[f\"{dirName[2]}\"] = []\n",
    "DATA[\"allFilesList\"] = []\n",
    "\n",
    "\n",
    "categorysCounts: dict = {}\n",
    "categorysCounts[f\"{dirName[0]}\"] = {}\n",
    "categorysCounts[f\"{dirName[1]}\"] = {}\n",
    "categorysCounts[f\"{dirName[2]}\"] = {}\n",
    "\n",
    "\n",
    "for index, dir in enumerate(dirName):\n",
    "    for folder in tqdm(Folders[index]):\n",
    "        files = os.listdir(f\"./{dir}/\" + folder)\n",
    "        for num, file in enumerate(files):\n",
    "            DATA[\"allFilesList\"].append(f\"./{dir}/\" + folder + \"/\" + file)\n",
    "            DATA[f\"{dir}\"].append(folder + \"/\" + file)\n",
    "            categorysCounts[f\"{dir}\"][folder] = num + 1\n",
    "\n",
    "for i in DATA.keys():\n",
    "    DATA[f\"{i}\"] = sorted(DATA[f\"{i}\"])\n",
    "\n",
    "\n",
    "def tdpsolaAug(xArray, yArray, path, percent, dataList, fileCounts):\n",
    "    for index, file in tqdm(enumerate(dataList)):\n",
    "        file = path + file\n",
    "        try:\n",
    "            st: dict = {}\n",
    "            start = 1\n",
    "            end = 3\n",
    "            for i in range(4):\n",
    "                st[i] = 2 ** (randint(start, end) / 12)\n",
    "                if i == 3:\n",
    "                    break\n",
    "                start += 3\n",
    "                end += 3\n",
    "            ps = random() > percent\n",
    "\n",
    "            xArray[index] = extractFeatures(file)\n",
    "            yArray[index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts + index] = extractFeatures(file, ps=ps, st=st[0])\n",
    "            yArray[fileCounts + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts * 2 + index] = extractFeatures(file, ps=ps, st=st[1])\n",
    "            yArray[fileCounts * 2 + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts * 3 + index] = extractFeatures(file, ps=ps, st=st[2])\n",
    "            yArray[fileCounts * 3 + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts * 4 + index] = extractFeatures(file, ps=ps, st=st[3])\n",
    "            yArray[fileCounts * 4 + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "        except ValueError:\n",
    "            print(index, file, ValueError)\n",
    "    return (xArray, yArray)\n",
    "\n",
    "\n",
    "def librosaAug(xArray, yArray, path, percent, dataList, fileCounts):\n",
    "    for index, file in tqdm(enumerate(dataList)):\n",
    "        file = path + file\n",
    "        try:\n",
    "            st = uniform(1.0, 2.0)\n",
    "            st2 = uniform(2.0, 3.0)\n",
    "            st3 = uniform(3.0, 5.0)\n",
    "            st4 = uniform(5.0, 7.0)\n",
    "            ps = random() > percent\n",
    "\n",
    "            xArray[index] = extractFeatures(file)\n",
    "            yArray[index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts + index] = extractFeatures(file, ps=ps, st=st)\n",
    "            yArray[fileCounts + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts * 2 + index] = extractFeatures(file, ps=ps, st=st2)\n",
    "            yArray[fileCounts * 2 + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts * 3 + index] = extractFeatures(file, ps=ps, st=st3)\n",
    "            yArray[fileCounts * 3 + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "            xArray[fileCounts * 4 + index] = extractFeatures(file, ps=ps, st=st4)\n",
    "            yArray[fileCounts * 4 + index] = np.int8(file.rsplit(\"/\", 2)[1])\n",
    "        except ValueError:\n",
    "            print(index, file, ValueError)\n",
    "    return (xArray, yArray)\n",
    "\n",
    "\n",
    "def extractFeatures(\n",
    "    path: str, ps: bool = False, ts: bool = False, st: int = 4\n",
    ") -> np.ndarray:\n",
    "    \"\"\"[提取特徵]\n",
    "    \n",
    "    Arguments:\n",
    "        path {str} -- [路徑]\n",
    "        ps {bool} \n",
    "    Returns:\n",
    "        np.ndarray -- \n",
    "               [\n",
    "                mfccs,\n",
    "                mfcc_delta,\n",
    "                mfcc_delta2,\n",
    "                chroma,\n",
    "                mel,\n",
    "                contrast,\n",
    "                tonnetz,\n",
    "                cent,\n",
    "                flatness,\n",
    "                rolloff,\n",
    "                rms,\n",
    "                ]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X, sampleRate = librosa.load(\n",
    "            path, offset=0.0, res_type=\"kaiser_best\", dtype=np.float32,\n",
    "        )\n",
    "        if ps:\n",
    "            if METHOD == \"Librosa\":\n",
    "                X = librosa.effects.pitch_shift(X, sampleRate, n_steps=st)\n",
    "\n",
    "            if METHOD == \"TD-PSOLA\":\n",
    "                X = shift_pitch(X, sampleRate, st)\n",
    "\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sampleRate).T, axis=0)\n",
    "        tonnetz = np.mean(\n",
    "            librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sampleRate).T,\n",
    "            axis=0,\n",
    "        )\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sampleRate, n_mfcc=40).T, axis=0)\n",
    "        mfcc_delta = librosa.feature.delta(mfccs)  # TONY\n",
    "        mfcc_delta2 = librosa.feature.delta(mfccs, order=2)  # TONY\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sampleRate).T, axis=0)\n",
    "        contrast = np.mean(\n",
    "            librosa.feature.spectral_contrast(S=stft, sr=sampleRate).T, axis=0\n",
    "        )\n",
    "        ###### ADD NEW FEATURES (SPECTRAL RELATED)##### 24-SEP\n",
    "        cent = np.mean(librosa.feature.spectral_centroid(y=X, sr=sampleRate).T, axis=0)\n",
    "        flatness = np.mean(librosa.feature.spectral_flatness(y=X).T, axis=0)\n",
    "        rolloff = np.mean(\n",
    "            librosa.feature.spectral_rolloff(S=stft, sr=sampleRate).T, axis=0\n",
    "        )\n",
    "        rms = np.mean(librosa.feature.rms(S=stft).T, axis=0)\n",
    "        ext_features = np.hstack(\n",
    "            [\n",
    "                mfccs,\n",
    "                mfcc_delta,\n",
    "                mfcc_delta2,\n",
    "                chroma,\n",
    "                mel,\n",
    "                contrast,\n",
    "                tonnetz,\n",
    "                cent,\n",
    "                flatness,\n",
    "                rolloff,\n",
    "                rms,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file:%s\" % (path))\n",
    "        return None\n",
    "\n",
    "    return np.array(ext_features)\n",
    "\n",
    "\n",
    "def creatSets(\n",
    "    path: str, dataList: list, shape: int, ps: bool = False, st: float = 4\n",
    ") -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"[創建訓練資料]\n",
    "    \n",
    "    Arguments:\n",
    "        path {str} -- [路徑]\n",
    "        dataList {list} -- [檔案列表]\n",
    "        shape {tuple} -- [矩陣維度]\n",
    "    Returns:\n",
    "        [(np.ndarray, np.ndarray)] -- [(特徵,種類)]\n",
    "    \"\"\"\n",
    "    if METHOD == 'Morphvox_Pro':\n",
    "        xArray = np.zeros([len(dataList)*4, shape])\n",
    "        yArray = np.zeros([len(dataList)*4])\n",
    "        fileCount = len(dataList)\n",
    "        for num in MorphvoxPro:\n",
    "            now = fileCount*(num-1)\n",
    "\n",
    "            for index, file in tqdm(enumerate(dataList)):\n",
    "                file = path+ f\"-{num}/\" + file\n",
    "\n",
    "                try:\n",
    "                    xArray[now + index] = extractFeatures(file, ps=ps, st=st)\n",
    "                    yArray[now + index] = file.rsplit(\"/\", 2)[1]\n",
    "                except ValueError:\n",
    "                    print(index, file, ValueError)\n",
    "        return (xArray, yArray)\n",
    "    else:\n",
    "        xArray = np.zeros([len(dataList), shape])\n",
    "        yArray = np.zeros([len(dataList)])\n",
    "\n",
    "        for index, file in tqdm(enumerate(dataList)):\n",
    "            file = path + file\n",
    "            try:\n",
    "                xArray[index] = extractFeatures(file, ps=ps, st=st)\n",
    "                yArray[index] = file.rsplit(\"/\", 2)[1]\n",
    "            except ValueError:\n",
    "                print(index, file, ValueError)\n",
    "        return (xArray, yArray)\n",
    "\n",
    "\n",
    "def creatAugmentSets(\n",
    "    path: str, dataList: list, shape: int, percent: float = 0\n",
    ") -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"[創建訓練資料]\n",
    "    \n",
    "    Arguments:\n",
    "        path {str} -- [路徑]\n",
    "        dataList {list} -- [檔案列表]\n",
    "        shape {tuple} -- [矩陣維度]\n",
    "    Returns:\n",
    "        [(np.ndarray, np.ndarray)] -- [(特徵,種類)]\n",
    "    \"\"\"\n",
    "    fileCounts = len(dataList)\n",
    "    xArray = np.zeros([fileCounts * 5, shape])\n",
    "    yArray = np.zeros([fileCounts * 5], dtype=np.int8)\n",
    "\n",
    "    if METHOD == \"Librosa\":\n",
    "        return librosaAug(xArray, yArray, path, percent, dataList, fileCounts)\n",
    "\n",
    "    if METHOD == \"TD-PSOLA\":\n",
    "        return tdpsolaAug(xArray, yArray, path, percent, dataList, fileCounts)\n",
    "\n",
    "\n",
    "def zScore(x):\n",
    "    return (x - np.mean(x, axis=0)) / np.std(x, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:25,  2.34it/s]\n",
      "200it [01:23,  2.38it/s]\n",
      "200it [01:22,  2.44it/s]\n",
      "200it [01:23,  2.40it/s]\n",
      "100it [00:41,  2.40it/s]\n",
      "100it [00:41,  2.40it/s]\n",
      "100it [00:41,  2.40it/s]\n",
      "100it [00:41,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "train = DATA[f'{dirName[0]}']\n",
    "valid = DATA[f'{dirName[1]}']\n",
    "test = DATA[f'{dirName[2]}']\n",
    "\n",
    "if METHOD == 'Morphvox_Pro':\n",
    "    trainData, trainLabel = creatSets(\n",
    "    f\"./{dirName[0]}\", train, extractFeatures(f\"./{dirName[0]}/\" + train[0]).shape[0], False\n",
    ")\n",
    "    pitchShiftTestData, pitchShiftTestLabel = creatSets(\n",
    "        f\"./{dirName[2]}\",\n",
    "        test,\n",
    "        extractFeatures(f\"./{dirName[2]}/\" + test[3]).shape[0],\n",
    "        False\n",
    "    )\n",
    "    \n",
    "else :    \n",
    "    trainData, trainLabel = creatAugmentSets(\n",
    "        f\"./{dirName[0]}/\", train, extractFeatures(f\"./{dirName[0]}/\" + train[0]).shape[0], 0\n",
    "    )\n",
    "    validData, validLabel = creatSets(\n",
    "        f\"./{dirName[1]}/\", valid, extractFeatures(f\"./{dirName[1]}/\" + valid[0]).shape[0], False\n",
    "    )\n",
    "    pitchShiftTestData, pitchShiftTestLabel = creatSets(\n",
    "        f\"./{dirName[2]}/\",\n",
    "        test,\n",
    "        extractFeatures(f\"./{dirName[2]}/\" + test[3]).shape[0],\n",
    "        True,\n",
    "        3,\n",
    "    )\n",
    "\n",
    "# if METHOD == 'Morphvox_Pro':\n",
    "#     pass\n",
    "# else:\n",
    "#     validData, validLabel = creatSets(\n",
    "#         f\"./{dirName[1]}/\", valid, extractFeatures(f\"./{dirName[1]}/\" + valid[0]).shape[0], False\n",
    "#     )\n",
    "    \n",
    "# if METHOD == 'Morphvox_Pro':\n",
    "#     pitchShiftTestData, pitchShiftTestLabel = creatSets(\n",
    "#         f\"./{dirName[2]}/\",\n",
    "#         test,\n",
    "#         extractFeatures(f\"./{dirName[2]}/\" + test[3]).shape[0],\n",
    "#          False\n",
    "#     )\n",
    "# else:\n",
    "#     pitchShiftTestData, pitchShiftTestLabel = creatSets(\n",
    "#         f\"./{dirName[2]}/\",\n",
    "#         test,\n",
    "#         extractFeatures(f\"./{dirName[2]}/\" + test[3]).shape[0],\n",
    "#         True,\n",
    "#         3,\n",
    "#     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 儲存資料\n",
    "- 訓練資料\n",
    "- 驗證資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(trainData.shape[0])\n",
    "trainData = trainData[indices]\n",
    "trainLabel = trainLabel[indices]\n",
    "\n",
    "# indices = np.random.permutation(validData.shape[0])\n",
    "# validData = validData[indices]\n",
    "# validLabel = validLabel[indices]\n",
    "\n",
    "indices = np.random.permutation(pitchShiftTestData.shape[0])\n",
    "pitchShiftTestData = pitchShiftTestData[indices]\n",
    "pitchShiftTestLabel = pitchShiftTestLabel[indices]\n",
    "\n",
    "np.save(f\"./pre-train/{METHOD}/Data-{dirName[0]}.npy\", zScore(trainData))\n",
    "np.save(f\"./pre-train/{METHOD}/Label-{dirName[0]}.npy\", trainLabel.astype(np.int))\n",
    "\n",
    "# np.save(f\"./pre-valid/{METHOD}/Data-{dirName[1]}.npy\", zScore(validData))\n",
    "# np.save(f\"./pre-valid/{METHOD}/Label-{dirName[1]}.npy\", validLabel.astype(np.int))\n",
    "\n",
    "np.save(f\"./pre-test/{METHOD}/Data-{dirName[2]}.npy\", zScore(pitchShiftTestData))\n",
    "np.save(f\"./pre-test/{METHOD}/Label-{dirName[2]}.npy\", pitchShiftTestLabel.astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.53691879e+02,  4.54857979e+01, -1.02507162e+01, -4.97274971e+00,\n",
       "       -8.14116573e+00, -7.54595375e+00, -2.09653130e+01, -3.38821816e+00,\n",
       "       -1.83881588e+01, -1.72183645e+00,  1.88315821e+00, -8.38461781e+00,\n",
       "        2.69371247e+00,  4.72468090e+00,  2.83916108e-02,  6.51459074e+00,\n",
       "        5.42296886e+00,  4.56653643e+00,  6.70677757e+00,  5.69498110e+00,\n",
       "        2.81431818e+00,  4.43500757e+00,  2.06860900e+00,  5.86426258e+00,\n",
       "       -8.99468124e-01,  7.17351484e+00, -1.36283219e+00,  5.95177126e+00,\n",
       "        2.02922297e+00,  3.82766747e+00,  1.59550858e+00,  3.26741695e+00,\n",
       "       -4.03967559e-01,  5.06316566e+00,  1.71078372e+00,  6.10415030e+00,\n",
       "        2.79120231e+00,  7.23617077e+00,  1.61583018e+00,  4.15990829e+00,\n",
       "        1.28431740e+01,  1.28431740e+01,  1.28431740e+01,  1.28431740e+01,\n",
       "        1.28431740e+01, -3.71496582e+00,  6.99199796e-01,  5.10848165e-01,\n",
       "        1.46978080e+00,  2.17230225e+00,  2.39690804e+00,  1.80940795e+00,\n",
       "        2.15589261e+00,  1.04843366e+00,  1.08993936e+00,  1.22393131e+00,\n",
       "        2.46700689e-01,  1.14061266e-01, -3.61122787e-02, -2.80331820e-01,\n",
       "       -5.32214642e-01, -2.13299498e-01, -5.64019263e-01, -1.49922550e-01,\n",
       "       -6.90620020e-02, -4.72644195e-02, -5.61091416e-02, -1.03368200e-01,\n",
       "       -9.90618914e-02, -1.89453766e-01,  7.00335875e-02,  2.09531095e-03,\n",
       "        1.98394418e-01,  4.16821867e-01,  3.23647857e-01,  2.50929803e-01,\n",
       "        2.50929803e-01,  2.50929803e-01,  2.50929803e-01,  2.50929803e-01,\n",
       "       -1.44982433e+01, -1.44982433e+01, -1.44982433e+01, -1.44982433e+01,\n",
       "       -1.44982433e+01,  3.76089978e+00,  1.16075337e+00,  8.50873053e-01,\n",
       "        7.42962420e-01,  4.37895209e-01, -6.86529040e-01,  5.38590066e-02,\n",
       "       -7.28189945e-01,  1.07907318e-02, -9.25914869e-02, -6.64071620e-01,\n",
       "       -2.67440259e-01, -2.57235378e-01, -5.17568052e-01,  1.10992067e-01,\n",
       "       -2.14341238e-01,  2.27681249e-01,  1.71674658e-02,  2.29958102e-01,\n",
       "       -2.10490124e-03,  1.30952954e-01, -7.46157095e-02,  9.13112164e-02,\n",
       "       -3.72523814e-01,  2.56130219e-01, -1.70306161e-01,  4.48083669e-01,\n",
       "        9.63284448e-02,  3.07451785e-01, -1.72543988e-01, -1.74379468e-01,\n",
       "       -1.74379468e-01, -1.74379468e-01, -1.74379468e-01, -1.74379468e-01,\n",
       "        5.41257739e-01,  5.47632694e-01,  5.73467255e-01,  6.06590390e-01,\n",
       "        6.88531697e-01,  6.95446312e-01,  7.17861116e-01,  7.39682198e-01,\n",
       "        7.28094399e-01,  6.89288437e-01,  6.74489856e-01,  6.37354374e-01,\n",
       "        5.60251534e-01,  6.45537162e-03,  5.00690565e-03,  6.19355729e-03,\n",
       "        1.25237713e-02,  2.09043864e-02,  5.77730499e-02,  6.66627511e-02,\n",
       "        8.97537470e-02,  1.23677768e-01,  2.45810211e-01,  1.90046346e+00,\n",
       "        4.56261015e+00,  4.86983013e+00,  1.17438860e+01,  1.08397961e+01,\n",
       "        1.47421942e+01,  3.24487267e+01,  5.23928680e+01,  1.06849833e+01,\n",
       "        1.28069639e+00,  2.08025169e+00,  2.47986746e+00,  9.54253137e-01,\n",
       "        1.13399899e+00,  1.16523552e+00,  9.26794827e-01,  1.55109453e+00,\n",
       "        2.48049974e+00,  7.19806004e+00,  1.50800705e+00,  6.21801555e-01,\n",
       "        3.96587342e-01,  3.32251221e-01,  2.80138421e+00,  3.90366554e+00,\n",
       "        3.49253249e+00,  2.05010033e+00,  5.46115279e-01,  3.79706144e-01,\n",
       "        5.51138520e-01,  2.12779689e+00,  3.00581765e+00,  2.21992803e+00,\n",
       "        1.26481652e+00,  3.25409293e-01,  5.84489822e-01,  1.33101714e+00,\n",
       "        2.12137485e+00,  1.35639584e+00,  5.76140344e-01,  1.02627563e+00,\n",
       "        2.51845908e+00,  2.78662086e+00,  3.87451768e+00,  1.46878111e+00,\n",
       "        7.21220613e-01,  8.12492609e-01,  1.05315650e+00,  1.12661862e+00,\n",
       "        3.64196718e-01,  3.89234126e-01,  3.01338255e-01,  4.00293350e-01,\n",
       "        1.74055979e-01,  7.98014551e-02,  1.05336860e-01,  7.66474307e-02,\n",
       "        5.22071272e-02,  8.21656659e-02,  9.27752927e-02,  4.37410064e-02,\n",
       "        8.52895081e-02,  9.37712789e-02,  6.72799498e-02,  9.52645242e-02,\n",
       "        8.72477517e-02,  1.02260783e-01,  1.06042847e-01,  7.89059550e-02,\n",
       "        9.01400074e-02,  1.40871674e-01,  1.46329150e-01,  1.01495616e-01,\n",
       "        7.05728233e-02,  2.91460287e-02,  1.69163272e-02,  1.17802834e-02,\n",
       "        8.90986715e-03,  7.29556568e-03,  6.51266892e-03,  6.66400557e-03,\n",
       "        8.63719359e-03,  6.82777492e-03,  7.43918726e-03,  7.70023093e-03,\n",
       "        8.68764240e-03,  9.44096688e-03,  1.19165452e-02,  1.87210795e-02,\n",
       "        4.31860201e-02,  9.89209116e-02,  8.96668732e-02,  7.98914656e-02,\n",
       "        5.41341491e-02,  4.81123701e-02,  4.25367579e-02,  3.23659144e-02,\n",
       "        3.82264778e-02,  5.88770881e-02,  1.38661295e-01,  2.65528142e-01,\n",
       "        3.22716892e-01,  1.63520217e-01,  1.16768375e-01,  8.38840082e-02,\n",
       "        3.85933518e-02,  2.51047444e-02,  1.32993879e-02,  9.82546899e-03,\n",
       "        1.35511244e-02,  2.45770458e-02,  4.06249315e-02,  7.07315654e-02,\n",
       "        6.58858791e-02,  8.04788917e-02,  1.63143929e-02,  6.13908691e-04,\n",
       "        2.59174942e+01,  1.60602900e+01,  1.65761215e+01,  1.44386418e+01,\n",
       "        1.66164560e+01,  1.62964027e+01,  3.10300823e+01,  4.03498606e-03,\n",
       "        6.82755316e-03,  1.18762343e-02,  8.65973778e-03,  9.31316706e-03,\n",
       "        1.53199302e-03,  3.02469933e+03,  5.07216044e-02,  6.59061886e+03,\n",
       "        3.37932993e-02])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitchShiftTestData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extractMelSpec(\n",
    "#     path: str, flip: bool = False, ps: bool = False, st: int = 4\n",
    "# ) -> np.ndarray:\n",
    "#     \"\"\"[提取mel頻譜]\n",
    "\n",
    "#     Arguments:\n",
    "#         path {str} -- [路徑]\n",
    "\n",
    "#     Keyword Arguments:\n",
    "#         flip {bool} -- [矩陣反轉] (default: {False})\n",
    "#         ps {bool} -- [是否調整音階]] (default: {False})\n",
    "#         st {int} -- [調整幾階]] (default: {4})\n",
    "\n",
    "#     Returns:\n",
    "#         np.ndarray -- [mel頻譜]\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         sig, rate = librosa.load(\n",
    "#             path, offset=0.0, res_type=\"kaiser_fast\", dtype=np.float32\n",
    "#         )\n",
    "#         if len(sig) < 22050:  # pad shorter than 1 sec audio with ramp to zero\n",
    "#             sig = np.pad(sig, (0, 22050 - len(sig)), \"linear_ramp\")\n",
    "#         if ps:\n",
    "#             sig = librosa.effects.pitch_shift(sig, rate, n_steps=st)\n",
    "#         db = librosa.amplitude_to_db(\n",
    "#             librosa.stft(sig[:22050], hop_length=256, center=False), ref=np.max\n",
    "#         )\n",
    "#         spec = librosa.feature.melspectrogram(S=db, n_mels=128).T\n",
    "#         if flip:\n",
    "#             spec = np.flipud(spec)\n",
    "#     except Exception as e:\n",
    "#         print(\"Error encountered while parsing file:%s\" % (path))\n",
    "#         return None\n",
    "#     return spec.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# def creatMelSpecSets(\n",
    "#     path: str, dataList: list, shape: tuple\n",
    "# ) -> (np.ndarray, np.ndarray):\n",
    "#     \"\"\"[創建訓練梅爾頻譜資料]\n",
    "\n",
    "#     Arguments:\n",
    "#         path {str} -- [路徑]\n",
    "#         dataList {list} -- [檔案列表]\n",
    "#         shape {tuple} -- [矩陣維度]\n",
    "#     Returns:\n",
    "#         [(np.ndarray, np.ndarray)] -- [(特徵,種類)]\n",
    "#     \"\"\"\n",
    "#     shape1, shape2 = shape\n",
    "#     xArray = np.zeros([len(dataList), shape1, shape2])\n",
    "#     yArray = np.zeros([len(dataList)])\n",
    "#     for index, file in enumerate(dataList):\n",
    "#         file = path + file\n",
    "#         try:\n",
    "#             xArray[index] = extractMelSpec(file)\n",
    "#             yArray[index] = file.rsplit(\"/\", 2)[1]\n",
    "#         except ValueError:\n",
    "#             print(index, file, ValueError)\n",
    "#     return (xArray, yArray)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# melTrainData, melTrainLabel = creatMelSpecSets(\n",
    "#     \"./train/\", trainList, extractMelSpec(\"./train/\" + trainList[0]).shape\n",
    "# )\n",
    "\n",
    "# melValidData, melValidLabel = creatMelSpecSets(\n",
    "#     \"./valid/\", validList, extractMelSpec(\"./valid/\" + validList[0]).shape\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合併\n",
    "for index ,data in enumerate([\"Librosa\",\"Morphvox_Pro\",\"TD-PSOLA\"]):\n",
    "    temp1 = np.load(f\"./pre-train/{data}/Data-train.npy\", allow_pickle=True)\n",
    "    temp2 = np.load(f\"./pre-train/{data}/Label-train.npy\", allow_pickle=True)\n",
    "    temp3 = np.load(f\"./pre-test/{data}/Data-pitchShiftTest.npy\", allow_pickle=True)\n",
    "    temp4 = np.load(f\"./pre-test/{data}/Label-pitchShiftTest.npy\", allow_pickle=True)\n",
    "    if index == 0 :\n",
    "        trainData = temp1\n",
    "        trainLabel = temp2\n",
    "        testData = temp3\n",
    "        testLabel = temp4\n",
    "        continue\n",
    "    trainData = np.concatenate((trainData, temp1), axis=0)\n",
    "    trainLabel = np.concatenate((trainLabel, temp2), axis=0)\n",
    "    testData = np.concatenate((testData, temp3), axis=0)\n",
    "    testLabel = np.concatenate((testLabel, temp4), axis=0)\n",
    "#打亂   \n",
    "indices = np.random.permutation(trainData.shape[0])\n",
    "trainData = trainData[indices]\n",
    "trainLabel = trainLabel[indices]\n",
    "indices = np.random.permutation(testData.shape[0])\n",
    "testData = testData[indices]\n",
    "testLabel = testLabel[indices]\n",
    "#儲存\n",
    "np.save(f\"./pre-train/Data-All.npy\", trainData)\n",
    "np.save(f\"./pre-train/Label-All.npy\", trainLabel.astype(np.int))\n",
    "np.save(f\"./pre-test/Data-All.npy\", testData)\n",
    "np.save(f\"./pre-test/Label-All.npy\", testLabel.astype(np.int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 277)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.26007578, -0.58986551,  0.02692549, ..., -0.16740027,\n",
       "       -0.01936643, -0.0170258 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((a), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(trainData.shape[0])\n",
    "trainData = trainData[indices]\n",
    "trainLabel = trainLabel[indices]\n",
    "indices = np.random.permutation(pitchShiftTestData.shape[0])\n",
    "testData = testData[indices]\n",
    "testLabel = testLabel[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"./pre-train/Data-All.npy\", trainData)\n",
    "np.save(f\"./pre-train/Label-All.npy\", trainLabel.astype(np.int))\n",
    "np.save(f\"./pre-test/Data-All.npy\", testData)\n",
    "np.save(f\"./pre-test/Label-All.npy\", testLabel.astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 6, ..., 1, 6, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
