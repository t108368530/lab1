{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from os import listdir, path, walk\n",
    "from random import randint, random, uniform\n",
    "from typing import Dict, List\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class data_path:\n",
    "    first_path: List[str] = []\n",
    "    file_path: Dict[str, List[str]] = {}\n",
    "    def __init__(self,low_bound: int,upper_bound: int,interval: int):\n",
    "        pass\n",
    "\n",
    "    def __get_first_path(self,low_bound,upper_bound,interval) -> List[str]:\n",
    "        pass\n",
    "\n",
    "    def __get_file_path(self, paths: str = './', limit: int = 1, depth: int = 0) -> List[List[str]]:\n",
    "        pass\n",
    "\n",
    "    def __gen_file_path(self):\n",
    "        def map_data(ggwp: str):\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class gen_dataset_file_path(data_path):\n",
    "\n",
    "    def __init__(self,low_bound,upper_bound,interval):\n",
    "        self.first_path = self.__get_first_path(low_bound,upper_bound,interval)\n",
    "        self.__gen_file_path()\n",
    "\n",
    "    def __get_first_path(self,low_bound,upper_bound,interval):\n",
    "        return reduce(lambda a, b: a + b, [[f\"./train{i}\", f\"./pitchShiftTest{i}\"] for i in range(low_bound  ,upper_bound + interval ,interval)])\n",
    "\n",
    "    def __get_file_path(self, paths='./', limit=1, depth=0):\n",
    "        for root, dirs, files in walk(paths):\n",
    "            if dirs or files:\n",
    "                depth += 1\n",
    "            if dirs and (depth <= limit):\n",
    "                return (self.__get_file_path(path.join(root, d), limit, depth) for d in dirs)\n",
    "            if files:\n",
    "                return [path.join(root, f) for f in files]\n",
    "\n",
    "    def __gen_file_path(self):\n",
    "        def map_data(ggwp):\n",
    "            self.file_path[ggwp] = reduce(\n",
    "                lambda a, b: a + b, self.__get_file_path(ggwp))\n",
    "        list(map(map_data, self.first_path))\n",
    "        \n",
    "class features(gen_dataset_file_path):\n",
    "    \n",
    "    def __init__(self,sample_rate ,low_bound,upper_bound,interval):\n",
    "        super().__init__(low_bound,upper_bound,interval)\n",
    "        self.sample_rate = sample_rate\n",
    "    \n",
    "    def __extract_features(self,path: str) -> np.ndarray:\n",
    "        pass\n",
    "    \n",
    "    def creat(self,shape: int,file_path: Dict[str, List[str]]):\n",
    "        pass \n",
    "\n",
    "class creat_data_sets(features):\n",
    "    \n",
    "    def __init__(self,sample_rate = 3000,low_bound = 9000 ,upper_bound = 13000,interval = 1000,method = \"Default\"):\n",
    "        super().__init__(sample_rate ,low_bound,upper_bound,interval,)\n",
    "        self.__get_one_file_path = self.file_path[self.first_path[0]][0]\n",
    "        self.shape = self.__extract_features(self.__get_one_file_path).shape[0]\n",
    "        self.__method = method\n",
    "        self.final_data_sets = {}\n",
    "        self.__switch = {\n",
    "            'Default':self.__case1\n",
    "        }\n",
    "        self.creat(self.shape,self.file_path,self.__method)\n",
    " \n",
    "    def __case1(self,shape,dataList):\n",
    "        xArray = np.zeros([len(dataList), shape])\n",
    "        yArray = np.zeros([len(dataList)])\n",
    "\n",
    "        for index, file in enumerate(dataList):\n",
    "            try:\n",
    "                xArray[index] = self.__extract_features(file)\n",
    "                yArray[index] = file.rsplit(\"/\", 2)[1]\n",
    "            except ValueError:\n",
    "                print(index, file, ValueError)\n",
    "        return (xArray, yArray)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __extract_features(self,path):\n",
    "        try:\n",
    "#             print(self.sample_rate)\n",
    "            X, sampleRate = librosa.load(\n",
    "                path, sr=self.sample_rate, offset=0.0, res_type=\"kaiser_best\", dtype=np.float32,\n",
    "            )\n",
    "            spectral_contrast_fmin = 0.5 * sampleRate * 2**(-6)\n",
    "#             print(sampleRate)\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sampleRate).T, axis=0)\n",
    "            tonnetz = np.mean(\n",
    "                librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sampleRate).T,\n",
    "                axis=0,\n",
    "            )\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sampleRate, n_mfcc=40).T, axis=0)\n",
    "            mfcc_delta = librosa.feature.delta(mfccs)  # TONY\n",
    "            mfcc_delta2 = librosa.feature.delta(mfccs, order=2)  # TONY\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sampleRate).T, axis=0)\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sampleRate,fmin=spectral_contrast_fmin).T, axis=0)\n",
    "\n",
    "            ###### ADD NEW FEATURES (SPECTRAL RELATED)##### 24-SEP\n",
    "            cent = np.mean(librosa.feature.spectral_centroid(y=X, sr=sampleRate).T, axis=0)\n",
    "            flatness = np.mean(librosa.feature.spectral_flatness(y=X).T, axis=0)\n",
    "            rolloff = np.mean(\n",
    "                librosa.feature.spectral_rolloff(S=stft, sr=sampleRate).T, axis=0\n",
    "            )\n",
    "            rms = np.mean(librosa.feature.rms(S=stft).T, axis=0)\n",
    "            ext_features = np.hstack(\n",
    "                [\n",
    "                    mfccs,\n",
    "                    mfcc_delta,\n",
    "                    mfcc_delta2,\n",
    "                    chroma,\n",
    "                    mel,\n",
    "                    contrast,\n",
    "                    tonnetz,\n",
    "                    cent,\n",
    "                    flatness,\n",
    "                    rolloff,\n",
    "                    rms,\n",
    "                ]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"Error encountered while parsing file:%s ,Error : %s\" % (path,e))\n",
    "            return None\n",
    "        \n",
    "        return np.array(ext_features)\n",
    "    \n",
    "    def creat(self,shape,file_path,method ):\n",
    "        kv = file_path\n",
    "        for key in kv:\n",
    "            self.final_data_sets[key] = self.__switch[method](shape,kv[key])\n",
    "                \n",
    "        \n",
    "def save_to_npy(datas: Dict,method ): \n",
    "    def zScore(x):\n",
    "        return (x - np.mean(x, axis=0)) / np.std(x, axis=0)\n",
    "    for key in datas.keys() :\n",
    "        if 'train' in key:\n",
    "            path = './pre-train'\n",
    "        elif 'Test' in key:\n",
    "            path = './pre-test'\n",
    "        file_name = key.replace('./','')\n",
    "        x ,y = datas[key][0],datas[key][1]\n",
    "        random_indices = np.random.permutation(x.shape[0])\n",
    "        x ,y = x[random_indices],y[random_indices]\n",
    "        data_npy_path = f\"{path}/{method}/Data-{file_name}.npy\"\n",
    "        label_npy_path = f\"{path}/{method}/Label-{file_name}.npy\"\n",
    "        np.save(data_npy_path, zScore(x))\n",
    "        np.save(label_npy_path, y.astype(np.int))\n",
    "\n",
    "def concatenate_npy(npy_path):\n",
    "    train_all_data =  np.load(f\"./pre-train/Data-All.npy\", allow_pickle=True)\n",
    "    train_all_label =  np.load(f\"./pre-train/Label-All.npy\", allow_pickle=True)\n",
    "    test_all_data =  np.load(f\"./pre-test/Data-All.npy\", allow_pickle=True)\n",
    "    test_all_label =  np.load(f\"./pre-test/Label-All.npy\", allow_pickle=True)\n",
    "    for index ,name in enumerate(npy_path):\n",
    "        name = name.replace('./','')\n",
    "        if index%2 == 0:\n",
    "            temp1 = np.load(f\"./pre-train/change_header/Data-{name}.npy\", allow_pickle=True)\n",
    "            temp2 = np.load(f\"./pre-train/change_header/Label-{name}.npy\", allow_pickle=True)\n",
    "            train_all_data = np.concatenate((train_all_data, temp1), axis=0)\n",
    "            train_all_label = np.concatenate((train_all_label, temp2), axis=0)\n",
    "            random_indices = np.random.permutation(train_all_data.shape[0])\n",
    "            train_all_data,train_all_label = train_all_data[random_indices],train_all_label[random_indices]\n",
    "        else :\n",
    "            temp1 = np.load(f\"./pre-test/change_header/Data-{name}.npy\", allow_pickle=True)\n",
    "            temp2 = np.load(f\"./pre-test/change_header/Label-{name}.npy\", allow_pickle=True)\n",
    "            test_all_data =  np.concatenate((test_all_data, temp1), axis=0)\n",
    "            test_all_label =  np.concatenate((test_all_label, temp2), axis=0)\n",
    "            random_indices = np.random.permutation(test_all_data.shape[0])\n",
    "            test_all_data,test_all_label = test_all_data[random_indices],test_all_label[random_indices]\n",
    "    return train_all_data,train_all_label,test_all_data,test_all_label\n",
    "\n",
    "def save_all_npy(train_all_data,train_all_label,test_all_data,test_all_label,method):\n",
    "    np.save(f\"./pre-train/Data-All-{method}.npy\", train_all_data)\n",
    "    np.save(f\"./pre-train/Label-All-{method}.npy\", train_all_label.astype(np.int))\n",
    "    np.save(f\"./pre-test/Data-All-{method}.npy\", test_all_data)\n",
    "    np.save(f\"./pre-test/Label-All-{method}.npy\", test_all_label.astype(np.int)) \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    data_sets = creat_data_sets(None,9000,13000,1000,\"Default\")\n",
    "    save_to_npy(data_sets.final_data_sets,'change_header')\n",
    "    train_all_data,train_all_label,test_all_data,test_all_label = concatenate_npy(data_sets.first_path)\n",
    "    save_all_npy(train_all_data,train_all_label,test_all_data,test_all_label,'change_header')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
